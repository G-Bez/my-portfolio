{
  "hash": "0da2a30f2bc2780dea6fa33afd25f652",
  "result": {
    "markdown": "---\ntitle: \"Case study - Cyclistic\"\ndate: \"2022-10-19\"\ncategories: [R, Case study]\nimage: cyclistic_thumbnail.jpeg\nformat:\n  html:\n    code-tools: true\n    fontsize: 0.9em\n    include-in-header: navbar.html\n    css: theme.css\n    toc: true\ncomments: \n    utterances: \n      repo:  G-Bez/my-portfolio \n      theme: photon-dark\ntitle-block-banner: false\neditor: visual\n---\n\n::: {.cell}\n<style type=\"text/css\">\n.justify {\n  text-align: justify !important\n}\n</style>\n:::\n\n\n## Introduction\n\n::: justify\nIn this case study we will perform real-world tasks of a junior data analyst, working for a fictional bike sharing company, called Cyclistic. This case study is taken from [Google data analytics professional certificate](https://www.coursera.org/professional-certificates/google-data-analytics) on Coursera.\n\nCyclistic's director of marketing believes the company's future success depends on maximizing the number of annual memberships. Therefore our (fictional) team wants to understand how casual riders and annual members differ. The final goal is to design a new marketing strategy to convert casuals into members, and more specifically, we need to answer two questions:\n\n-   How Cyclistic can increase its revenue based on the available data?\n-   How the marketing team can use social media to help with maximizing the number of members?\n\nBut first the marketing team recommendations must be backed up with compelling data insights and visualizations, in order to get approved by the management.\n:::\n\n## Packages\n\n::: justify\nHere is the list of packages we'll use throughout this case study.\n\n-   **data.table**: Fast data manipulation.\n-   **lubridate**: Datetime tools.\n-   **geosphere**: Spherical trigonometry for spatial applications.\n-   **rstatix**: Framework for basic statistical tests.\n-   **robustbase**: Basic robust statistics.\n-   **ggplot2**: Data visualization.\n-   **ggmap**: Spatial visualizations with for ggplot2 users.\n-   **viridisLite**: Colorblind friendly color palettes.\n-   **patchwork**: Easy plot composition for ggplot2 users.\n\nWe start by loading these packages.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(lubridate)\nlibrary(geosphere)\nlibrary(rstatix)\nlibrary(robustbase)\nlibrary(ggplot2)\nlibrary(ggmap)\nlibrary(viridisLite)\nlibrary(patchwork)\n```\n:::\n\n\n## Dataset\n\n::: justify\nThe relevant historical bike trip data can be downloaded from [this url](https://divvy-tripdata.s3.amazonaws.com/index.html) (see [license agreement](https://www.divvybikes.com/data-license-agreement)). Here we use data ranging from June 2021 to May 2022 (archives from \"202106-divvy-tripdata.zip\" to \"202205-divvy-tripdata.zip\" included).\n\nEach archive contains a single monthly dataset, where each observation represents a unique bike ride. Each dataset has 13 columns/variables:\n\n-   **ride_id**: alphanumeric id for each ride.\n-   **rideable_type**: Bike type. Categorical variable with 3 levels: \"classic_bike\", \"docked_bike\", \"electric_bike\".\n-   **member_casual**: Customer type. Categorical variable with 2 levels: \"casual\", \"member\".\n-   **started_at**: Ride start datetime.\n-   **ended_at**: Ride end datetime.\n-   **start_station_name**: Name of the start station.\n-   **start_station_id**: Alphanumeric id for start station.\n-   **end_station_name**: Name of the end station.\n-   **end_station_id**: Alphanumeric id for end station.\n-   **start_lat**: Start latitude coordinate.\n-   **start_lng**: Start longitude coordinate.\n-   **end_lat**: End latitude coordinate.\n-   **end_lng**: End longitude coordinate.\n:::\n\n## Data scraping and manipulation\n\n::: justify\nAs first step, we scrape the datasets, merge them into a total dataset, and do some manipulation. In particular we add some additional columns, computed from the existing ones:\n\n-   **ride_length**: Ride length in seconds ('ended_at' - 'started_at').\n-   **year_month**: Year and month value extracted from 'started_at' variable.\n-   **weekday**: Day of week extracted from 'started_at' variable.\n-   **ride_dist**: Mileage in meters. Computed from latitude and longitude values.\n\nThen we convert 'year_month' and 'member_casual' variables into factor datatype, and 'year_month' into ordered factor. To accomplish these tasks we use 3 custom functions.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Custom scraping and manipulation functions\"}\nadd.cols <- function(dt) {\n  if(!(\"data.table\" %in% class(dt))) stop(\"dt is not a data.table object.\")\n  if(Sys.getlocale(\"LC_TIME\") != \"English_United States.1252\") Sys.setlocale(\"LC_TIME\", \"English\")\n  year_month <- format(dt$started_at, \"%b %Y\")\n  weekday <- lubridate::wday(dt$started_at, label = T, abbr = T, week_start = 1)\n  ride_length <- as.numeric(dt$ended_at - dt$started_at)\n  ride_dist = geosphere::distGeo(p1 = dt[, c(\"start_lng\", \"start_lat\"), with = F], \n                                 p2 = dt[, c(\"end_lng\", \"end_lat\"), with = F])\n  return(cbind(dt, year_month, weekday, ride_length, ride_dist))\n}\n\n\nchange.datatypes <- function(dt) {\n  if(!(\"data.table\" %in% class(dt))) stop(\"dt is not a data.table object.\")\n  dt[, c(\"rideable_type\", \"member_casual\")] <- lapply(\n    dt[, c(\"rideable_type\", \"member_casual\")],\n    as.factor\n  )\n  dt[[\"year_month\"]] <- ordered(dt[[\"year_month\"]], levels = unique(dt$year_month))\n  return(dt)\n}\n\n\nget.raw_data <- function(Url, Timeout = 60) {   ## increase timeout if you get timeout error\n  mm <- c(\"202106\", \"202107\", \"202108\", \"202109\", \"202110\", \"202111\", \"202112\", \"202201\",\n          \"202202\", \"202203\", \"202204\", \"202205\")\n  url1 <- Url\n  urls <- lapply(url1, paste, mm, \"-divvy-tripdata.zip\", sep = \"\")[[1]]\n  \n  ls <- vector(mode = \"list\", length = length(mm))\n  names(ls) <- paste(mm, \"-divvy-tripdata.csv\", sep = \"\")\n  \n  options(timeout = Timeout)\n  for (i in 1:length(ls)) {\n    ls[[i]] <- tempfile(fileext = \".zip\")\n    download.file(urls[i], ls[[i]])\n    ls[[i]] <- unzip(ls[[i]], names(ls)[i], exdir = tempdir()) |> \n      data.table::fread(na.strings = c(\"\", NA))\n  }\n  options(timeout = 60)\n  \n  raw.tot_data <- data.table::rbindlist(ls) |> add.cols() |> change.datatypes() |> \n    data.table::setcolorder(c(1,2,13,3,4,16,14,15,5:12,17)) |> \n    data.table::setkey(ride_id)\n  \n  invisible(gc(reset = T))\n  return(raw.tot_data)\n}\n```\n:::\n\n\n::: justify\nWe call the resulting dataset 'raw.tot_data'.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://divvy-tripdata.s3.amazonaws.com/\"\nraw.tot_data <- get.raw_data(url, Timeout = 5000)\n```\n:::\n\n\n::: {.callout-note collapse=\"false\"}\n::: callout-note\n## Note:\n\nThe datasets are quite large (more then 5 million obs. total). If you wish to reproduce this analysis keep in mind it might take much time, even more than 1 hour with non recent hardware.\n:::\n:::\n\n## Data cleansing\n\n::: justify\nAs next step we do some data cleansing. We must deal with missing and bad values, which the raw dataset has plenty of.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(miss_val = lapply(raw.tot_data, is.na) |> lapply(sum))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   miss_val\nride_id            0       \nrideable_type      0       \nmember_casual      0       \nstarted_at         0       \nended_at           0       \nride_length        0       \nyear_month         0       \nweekday            0       \nstart_station_name 823167  \nstart_station_id   823164  \nend_station_name   878338  \nend_station_id     878338  \nstart_lat          0       \nstart_lng          0       \nend_lat            5036    \nend_lng            5036    \nride_dist          5036    \n```\n:::\n:::\n\n\n::: justify\nWe use two additional custom functions to accomplish this task.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Custom cleansing functions\"}\nrm.outliers <- function(data) {\n  if(!(\"data.table\" %in% class(data))) stop(\"dt is not a data.table object.\")\n  rl.upp_whisk <- robustbase::adjboxStats(data[ride_length > 0, ride_length])$stats[5]\n  df <- data[-which(ride_length < 0 | ride_length > rl.upp_whisk\n                    | (ride_dist == 0 & start_station_name != end_station_name)\n                    | (ride_dist != 0 & start_station_name == end_station_name)\n                    | ride_dist %in% data[order(-ride_dist), head(.SD, 2)]$ride_dist)]\n  return(df)\n}\n\n\nrm.missing <- function(data) {\n  if(!(\"data.table\" %in% class(data))) stop(\"dt is not a data.table object.\")\n  df <- data[, grep(\"*station\", names(data)) := NULL]\n  df <- df[complete.cases(df)]\n  return(df)\n}\n```\n:::\n\n\n::: justify\nThis is what the two functions do:\n\n-   Drop obs. with 'ride_length' \\< 0, since negative times don't make sense.\n-   Drop obs. with 'ride_length' \\> extreme of upper whisker of its boxplot adjusted for skewed distributions (see `robustbase::adjboxStats()` documentation).\n-   Drop obs. with 'ride_dist' = 0, and 'start_station_name' != 'end_station_name', since null distance only makes sense when start station and end station are the same.\n-   Drop obs. with 'ride_dist' != 0, and 'start_station_name' = 'end_station_name'.\n-   Drop the two highest 'ride_dist' values, since max value is physically impossible, and the second highest one, while it might make sense in theory, is also an extremely far outlier compared to other values.\n-   Drop station IDs and names variables, since they have many non imputable values, and we won't use those variables in the following analysis.\n-   Drop rows with missing 'end_lat', 'end_lng' and 'ride_dist' values.\n\n::: callout-warning\n## Warning!\n\nArbitrarily removing observations from datasets is bad practice in real case scenarios, and might lead to strongly biased results. Always confront with your team and project stakeholders before removing any observation. However this is only a fictional case study, and this is the best we can do here.\n:::\n\nWe now run the two custom functions, and assign the output to 'tot_data'. This is the final dataset we'll use throughout the rest of the analysis. It has 5.673.722 rows and 13 columns.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntot_data <- raw.tot_data |> rm.outliers() |> rm.missing()\nstr(tot_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nClasses 'data.table' and 'data.frame':\t5673721 obs. of  13 variables:\n $ ride_id      : chr  \"00000123F60251E6\" \"000002EBE159AE82\" \"0000080D43BAA9E4\" \"00000B4F1F71F9C2\" ...\n $ rideable_type: Factor w/ 3 levels \"classic_bike\",..: 1 3 1 3 3 1 3 1 1 3 ...\n $ member_casual: Factor w/ 2 levels \"casual\",\"member\": 2 2 1 2 2 2 2 2 1 2 ...\n $ started_at   : POSIXct, format: \"2022-02-07 15:47:40\" \"2021-06-22 17:25:15\" ...\n $ ended_at     : POSIXct, format: \"2022-02-07 15:49:28\" \"2021-06-22 17:31:34\" ...\n $ ride_length  : num  108 379 2758 376 668 ...\n $ year_month   : Ord.factor w/ 12 levels \"Jun 2021\"<\"Jul 2021\"<..: 9 1 3 4 12 5 11 3 2 6 ...\n $ weekday      : Ord.factor w/ 7 levels \"Mon\"<\"Tue\"<\"Wed\"<..: 1 2 7 3 4 7 1 5 3 2 ...\n $ start_lat    : num  41.9 41.9 41.9 41.9 41.9 ...\n $ start_lng    : num  -87.6 -87.6 -87.6 -87.7 -87.6 ...\n $ end_lat      : num  41.9 41.9 41.9 41.9 41.9 ...\n $ end_lng      : num  -87.6 -87.6 -87.6 -87.7 -87.6 ...\n $ ride_dist    : num  361 1581 467 830 2441 ...\n - attr(*, \".internal.selfref\")=<externalptr> \n - attr(*, \"sorted\")= chr \"ride_id\"\n```\n:::\n:::\n\n\n## Explorative analysis\n\n::: justify\nNext step is a brief exploratory analysis. We start by looking at 'ride_length' and 'ride_dist' distributions, with boxplots grouped by 'member_casual' variable, being the main variable of interest for this case study. Again, we use a custom function to draw the boxplots, and we apply a custom ggplot2 theme.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Custom boxplot function\"}\nbox_plot <- function(data, x, y, mult=1, Fill = \"thistle2\", outl.size = 0.2, Notch = F, Coef = 1.5, \n                     stat = \"mean\", Breaks = waiver(), Title = \"Title\", Subtitle = waiver(), \n                     x.lab = \"x-axis label\", y.lab = \"y-axis label\") {\n  \n  x = parse(text = x)\n  y = parse(text = y)\n  \n  box <- ggplot2::ggplot(data, aes(x = eval(x), y = eval(y)*mult)) +\n    geom_boxplot(outlier.size = outl.size, fill = Fill, notch = Notch, coef = Coef) +\n    stat_summary(fun = stat) +\n    scale_y_continuous(breaks = Breaks) +\n    ggtitle(Title, Subtitle) +\n    xlab(x.lab) +\n    ylab(y.lab)\n  \n  return(box)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Custom ggplot2 theme\"}\ntheme_update(\n  axis.text = element_text(size = 11),\n  legend.background = element_blank(),\n  panel.background = element_rect(fill = \"grey85\"),\n  panel.border = element_rect(colour = \"black\", fill = NA),\n  panel.grid = element_line(colour = \"whitesmoke\"),\n  panel.grid.minor.y = element_blank(),\n  panel.grid.major.x = element_blank(),\n  plot.title = element_text(hjust = 0.5),\n  plot.subtitle = element_text(face = \"italic\", hjust = 0.5),\n  strip.background = element_rect(colour = \"black\", fill = \"grey85\"),\n  strip.text = element_text(size = 10, face = \"bold\"),\n  title = element_text(size = 12, face = \"bold\")\n)\n```\n:::\n\n\n::: justify\nBelow you can see the resulting plots:\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrl_box <- box_plot(tot_data, \"member_casual\", \"ride_length\", mult = 1/60,\n                        Fill =  viridisLite::turbo(25)[c(5,16)], Notch = T, Breaks = seq(0,90,5), \n                        Title = \"Ride length boxplots\", x.lab = \"Membership\",\n                        y.lab = \"Ride length (min.)\")\nrd_box <- box_plot(tot_data, \"member_casual\", \"ride_dist\", mult = 1/1000,\n                        Fill =  viridisLite::turbo(25)[c(5,16)], Notch = T, Breaks = seq(0,35,2.5), \n                        Title = \"Ride dist boxplots\", x.lab = \"Membership\", \n                        y.lab = \"Ride distance (km)\")\n\nrl_box + rd_box # patchwork composition\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/boxplots-1.png){width=90% height=90%}\n:::\n:::\n\n\n::: justify\nAll the four distributions are heavily right skewed, with mean (black dot) \\> median, long upper whiskers and many outliers on the upper side.\n\nLooking at 'ride_length' plot, we notice casuals group has higher variance than members one, since casuals box is wider. Also, all casuals boxplot statistics have higher values than their members counterparts. Hence it seems like casual customers have a tendency to take longer rides, and more diverse use cases for Cyclistic's bikes. Conversely, the two 'ride_dist' boxplots look very similar, suggesting the two groups cover the same distance on average. Additional more formal analysis is required here in order to draw conclusions. This preliminar graphical analysis suggests members are more likely to use Cyclistic's bikes for daily routine tasks, like commuting to work, compared to casual customers who occasionally rent them for leisure. Moreover, from the boxplots results, it's clear that the current Cyclistic strategy doesn't profit from 'ride_length', since members, being the most profitable group, take shorter rides.\n\nAs next step we compute some summary statistics for 'ride_length' and 'rideable_type' variables. We'll use them later to draw additional visualizations. Again we write a custom function to do it, in order to save keystrokes.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Custom summary function\"}\nSumm <- function(data, var, group_by, order_by = group_by) {\n  if(!(\"data.table\" %in% class(data))) stop(\"dt is not a data.table object.\")\n  \n  x = parse(text = var)\n  summ = data[\n    ,\n    .(obs = NROW(eval(x)), quart1 = quantile(eval(x), 0.25), mean = mean(eval(x)), \n      median = median(eval(x)), quart3 = quantile(eval(x), 0.75), iqr = IQR(eval(x)),\n      stdev = sd(eval(x))), \n    by = group_by\n  ] |> data.table::setorderv(cols = order_by)\n  \n  return(summ)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrl_summ_by_ym <- Summ(tot_data, \"ride_length\", c(\"member_casual\", \"year_month\"))\nrl_summ_by_wd <- Summ(tot_data, \"ride_length\", c(\"member_casual\", \"weekday\"))\nrt_summ <- tot_data[, .(obs = .N), by = c(\"member_casual\", \"rideable_type\")]\n```\n:::\n\n\n::: {#summaries .panel-tabset}\n## rl_summ_by_ym\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrl_summ_by_ym\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    member_casual year_month    obs quart1      mean median quart3    iqr\n 1:        casual   Jun 2021 343553  576.0 1283.0834    979   1673 1097.0\n 2:        casual   Jul 2021 413932  561.0 1245.7968    950   1619 1058.0\n 3:        casual   Aug 2021 388833  545.0 1213.8663    921   1575 1030.0\n 4:        casual   Sep 2021 344914  522.0 1178.2975    883   1525 1003.0\n 5:        casual   Oct 2021 244740  468.0 1078.4636    793   1389  921.0\n 6:        casual   Nov 2021 102833  395.0  918.5119    660   1162  767.0\n 7:        casual   Dec 2021  67023  387.5  892.8884    643   1132  744.5\n 8:        casual   Jan 2022  17810  363.0  805.6264    590   1008  645.0\n 9:        casual   Feb 2022  20405  387.0  880.3110    632   1110  723.0\n10:        casual   Mar 2022  84746  460.0 1127.8093    816   1489 1029.0\n11:        casual   Apr 2022 119640  452.0 1099.3256    795   1439  987.0\n12:        casual   May 2022 262577  501.0 1185.9838    875   1550 1049.0\n13:        member   Jun 2021 354758  373.0  817.9696    636   1075  702.0\n14:        member   Jul 2021 376543  365.0  802.9104    625   1052  687.0\n15:        member   Aug 2021 387775  357.0  793.4779    608   1037  680.0\n16:        member   Sep 2021 388197  343.0  770.8177    587   1002  659.0\n17:        member   Oct 2021 369407  307.0  698.4691    519    893  586.0\n18:        member   Nov 2021 249856  277.0  629.5316    461    787  510.0\n19:        member   Dec 2021 175515  275.0  620.9361    457    782  507.0\n20:        member   Jan 2022  84244  279.0  608.3621    448    753  474.0\n21:        member   Feb 2022  93157  275.0  616.9100    451    766  491.0\n22:        member   Mar 2022 191845  284.0  662.8775    482    839  555.0\n23:        member   Apr 2022 241999  277.0  651.5632    474    826  549.0\n24:        member   May 2022 349419  322.0  755.8451    564    983  661.0\n    member_casual year_month    obs quart1      mean median quart3    iqr\n        stdev\n 1: 1003.7459\n 2:  978.9981\n 3:  961.0095\n 4:  949.0889\n 5:  898.0429\n 6:  798.8552\n 7:  773.8583\n 8:  701.4893\n 9:  774.1430\n10:  956.9421\n11:  936.7498\n12:  985.0330\n13:  636.7139\n14:  630.3621\n15:  632.8731\n16:  620.8099\n17:  585.3930\n18:  540.6631\n19:  528.8499\n20:  519.2169\n21:  537.1952\n22:  575.2290\n23:  568.6321\n24:  632.8844\n        stdev\n```\n:::\n:::\n\n\n## rl_summ_by_wd\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrl_summ_by_wd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    member_casual weekday    obs quart1      mean median  quart3     iqr\n 1:        casual     Mon 282856    495 1178.6815    865 1546.00 1051.00\n 2:        casual     Tue 272242    462 1066.9628    780 1360.00  898.00\n 3:        casual     Wed 272028    464 1057.6846    780 1350.00  886.00\n 4:        casual     Thu 293717    468 1061.7332    783 1352.00  884.00\n 5:        casual     Fri 342166    491 1119.2363    833 1445.75  954.75\n 6:        casual     Sat 511457    570 1270.2624    976 1667.00 1097.00\n 7:        casual     Sun 436540    574 1300.8242    996 1710.00 1136.00\n 8:        member     Mon 460809    308  708.8109    525  910.00  602.00\n 9:        member     Tue 519256    308  690.7078    520  887.00  579.00\n10:        member     Wed 507258    312  697.7463    528  897.00  585.00\n11:        member     Thu 496600    312  699.4487    528  901.00  589.00\n12:        member     Fri 454393    315  713.9517    537  921.00  606.00\n13:        member     Sat 435214    349  811.2369    614 1063.00  714.00\n14:        member     Sun 389185    342  815.4492    607 1074.00  732.00\n        stdev\n 1:  977.6261\n 2:  901.7131\n 3:  884.0924\n 4:  886.1289\n 5:  918.3581\n 6:  989.3016\n 7: 1018.5658\n 8:  595.1113\n 9:  565.8532\n10:  569.0408\n11:  572.8629\n12:  588.8620\n13:  665.4548\n14:  681.0527\n```\n:::\n:::\n\n\n## rt_summ\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrt_summ\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   member_casual rideable_type     obs\n1:        member  classic_bike 1974193\n2:        member electric_bike 1288522\n3:        casual  classic_bike 1182884\n4:        casual   docked_bike  235153\n5:        casual electric_bike  992969\n```\n:::\n:::\n\n:::\n\n::: justify\nAs final step of our exploratory data analysis, we perform Welch's t-tests on 'ride_length' and 'ride_dist' variables means, with 'member_casual' being the grouping factor. We also compute Cohen's D estimates to see the actual effect size of 'member_casual' on the other two variables.\n\n::: {.callout-note collapse=\"False\"}\n## Note:\n\nSince we have a very large dataset, Welch's tests will almost certainly reject the null hypothesis of equal population means for member and casual customers. That's why we also estimate the actual effect sizes of 'member_casual' variable with Cohen's d statistics.\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwelch_rl <- t.test(ride_length ~ member_casual, data = tot_data)\nwelch_rd <- t.test(ride_dist ~ member_casual, data = tot_data)\n```\n:::\n\n\n::: {#welch .panel-tabset}\n## welch_rl\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwelch_rl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  ride_length by member_casual\nt = 630.05, df = 3806121, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group casual and group member is not equal to 0\n95 percent confidence interval:\n 440.0178 442.7640\nsample estimates:\nmean in group casual mean in group member \n           1171.2742             729.8833 \n```\n:::\n:::\n\n\n## welch_rd\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwelch_rd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  ride_dist by member_casual\nt = 123.77, df = 5074284, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group casual and group member is not equal to 0\n95 percent confidence interval:\n 199.2456 205.6576\nsample estimates:\nmean in group casual mean in group member \n            2303.351             2100.899 \n```\n:::\n:::\n\n:::\n\n::: justify\nAs expected, both tests reject the null hypothesis of equal population means. So let's see how strong the relationships between 'member_casuals', and 'ride_dist' and 'ride_length' variables actually are. Relying on the two boxplots, we can assume a moderate to high effect size on 'ride_length' variable, and a small effect size on 'ride_dist' variable.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohensD_rl <- rstatix::cohens_d(ride_length ~ member_casual, data = tot_data)\ncohensD_rd <- rstatix::cohens_d(ride_dist ~ member_casual, data = tot_data)\n```\n:::\n\n\n::: {#cohensD .panel-tabset}\n## cohensD_rl\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohensD_rl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  .y.         group1 group2 effsize      n1      n2 magnitude\n* <chr>       <chr>  <chr>    <dbl>   <int>   <int> <ord>    \n1 ride_length casual member   0.552 2411006 3262715 moderate \n```\n:::\n:::\n\n\n## cohensD_rd\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohensD_rd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  .y.       group1 group2 effsize      n1      n2 magnitude \n* <chr>     <chr>  <chr>    <dbl>   <int>   <int> <ord>     \n1 ride_dist casual member   0.105 2411006 3262715 negligible\n```\n:::\n:::\n\n:::\n\n::: justify\nAs expected, our assumptions about effect sizes turned out correct. 'member_casual' has a moderate effect size on 'ride_length' variable, and a negligible effect on 'ride_dist'. That's more evidence supporting our previous findings about the two types of customers: casuals tend to take significantly longer rides and are more likely to use Cyclistic bikes for leisure.\n:::\n\n## Visualizations\n\n::: justify\nLast step of our analysis consists of some additional visualizations about the total number of rides, and some maps.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Custom visualiz. functions\"}\ncol_plot <- function(data, x, y, group, mult = 1, Legend = F, text_vjust = 0, text_col = \"black\", \n                     text_fface = \"bold\", text.size = 2.5, facet_nrow = 2, facet_strip = \"right\", \n                     Breaks = waiver(), col_man = rep(\"black\", facet_nrow), \n                     Fill_man = rep(\"thistle2\", facet_nrow), Title = \"Title\", Subtitle = waiver(), \n                     x.lab = \"x-axis label\", y.lab = \"y-axis label\", Round = 2, Angle = 0) {\n  x = parse(text = x)\n  y = parse(text = y)\n  group = parse(text = group)\n  \n  col <- ggplot2::ggplot(data, aes(x = eval(x), y = eval(y)*mult)) +\n    geom_col(aes(color = eval(group), fill = eval(group)), show.legend = Legend) +\n    geom_text(aes(label = round(eval(y)*mult, Round)), \n              vjust = text_vjust, \n              colour = text_col, \n              fontface = text_fface, \n              size = text.size) +\n    facet_wrap(~eval(group), nrow = facet_nrow, strip.position = facet_strip) +\n    scale_y_continuous(breaks = Breaks) +\n    scale_color_manual(values = col_man) +\n    scale_fill_manual(values = Fill_man) +\n    theme(axis.text.x = element_text(angle = Angle)) +\n    ggtitle(Title, Subtitle) +\n    xlab(x.lab) +\n    ylab(y.lab)\n  \n  return(col)\n}\n\n\nmap_plot <- function(data, lng, lat, group, Zoom = 11, Crop = F, Type = \"toner-lite\", transp = 0.05,\n                     dot.size = 0.85, col_man = \"black\", fill_man = \"black\", x.lab = \"longitude\",\n                     y.lab = \"latitude\", Title = \"map\") {\n  lng = parse(text = lng)\n  lat = parse(text = lat)\n  group = parse(text = group)\n  \n  map.lim = c(min(data[, eval(lng)]), min(data[, eval(lat)]), \n              max(data[, eval(lng)]), max(data[, eval(lat)]))\n  map = get_stamenmap(bbox = map.lim, zoom = Zoom, maptype = Type, crop = Crop)\n  \n  map.plot <- ggmap::ggmap(map) +\n    geom_point(data = data, \n               aes(x = eval(lng), y = eval(lat), fill = eval(group), colour = eval(group)),\n               alpha = transp, size = dot.size) +\n    scale_color_manual(values = col_man) +\n    scale_fill_manual(values = fill_man) +\n    guides(colour = guide_legend(override.aes = list(alpha = 1, size = 1.5))) +\n    theme(legend.title = element_blank(), legend.position = c(0.80, 0.90),\n          legend.background = element_rect(colour = \"black\", size = 0.1)) +\n    xlab(x.lab) +\n    ylab(y.lab) +\n    ggtitle(label = Title)\n  \n  return(map.plot)\n}\n```\n:::\n\n\n::: justify\nBelow you can look at column plots for number of rides by month and by day of week, both grouped by 'member_casual'.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnr.ym <- col_plot(rl_summ_by_ym, \"year_month\", \"obs\", \"member_casual\", mult = 1/1000,\n                       text_vjust = 1.2, Breaks = seq(0, 500, 50), Title = \"Num. rides by month\",\n                       Fill_man = viridisLite::turbo(25)[c(5,16)], x.lab = \"Month\",\n                       y.lab = \"Num. rides (thousands)\", Round = 0, Angle = 90)\nnr.wd <- col_plot(rl_summ_by_wd, \"weekday\", \"obs\", \"member_casual\", mult = 1/1000,\n                       text_vjust = 5, Breaks = seq(0, 500, 50), Title = \"Num. rides by weekday\",\n                       Fill_man = viridisLite::turbo(25)[c(5,16)], x.lab = \"Weekday\",\n                       y.lab = \"Num. rides (thousands)\", Round = 0)\n\nnr.ym + nr.wd #patchwork composition\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/ride_length colplots-1.png){width=90% height=90%}\n:::\n:::\n\n\n::: justify\nThese plots are quite interesting. The first one shows an obvious decline of the number of rides in cold seasons, for both casual and member customers, but the decline is steeper for casual riders. The second plot shows plain different trends in the number of rides by day of week: casuals do ride more during the weekend, while members have an opposite trend, with maximum number of rides during mid-week, and a decline towards the weekend. Those are pretty strong evidences that annual members mostly use Cyclistic bike sharing service to commute to work, while casuals rent bikes for leisure, mainly.\n\nWith the following column plot we also take a look at customers preferences about bike types.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnr.rt <- ggplot(rt_summ, aes(x = rideable_type, y = obs/1000)) +\n    geom_col(aes(fill = member_casual), position = \"dodge\", colour = \"black\") +\n    geom_text(\n      aes(group = member_casual, label = round(obs/1000)), \n      position = position_dodge2(width = 1),\n      vjust = 2, fontface = \"bold\"\n    ) +\n    scale_fill_manual(values = viridisLite::turbo(25)[c(5,16)]) +\n    theme(legend.position = c(.85, .85), legend.title = element_blank()) +\n    ylab(\"Num. rides (thousands)\") +\n    xlab(\"Bike type\") + \n    ggtitle(\"Num. rides by bike type\")\n\nnr.rt\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/bike type colplot-1.png){width=90% height=90%}\n:::\n:::\n\n\n::: justify\nAs we can see, docked bikes ar by far the least popular category, and more important, those are only used by casual customers. It makes sense in accordance to previous findings, that annual members prefer the flexibility of non-docked bikes when commuting to work.\n\nEventually, we draw two maps paired with scatterplots of start and end coordinates.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_map <- map_plot(tot_data, \"start_lng\", \"start_lat\", \"member_casual\",\n                           col_man = viridisLite::turbo(25)[c(5,16)], \n                           fill_man = viridisLite::turbo(25)[c(5,16)], Title = \"Start map\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n```\n:::\n\n```{.r .cell-code}\nend_map <- map_plot(tot_data, \"end_lng\", \"end_lat\", \"member_casual\",\n                         col_man = viridisLite::turbo(25)[c(5,16)], \n                         fill_man = viridisLite::turbo(25)[c(5,16)], Title = \"End map\")\n\nstart_map + end_map #patchwork composition\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/maps-1.png){width=90% height=90%}\n:::\n:::\n\n\n::: justify\nThe two maps clearly show that member customers are Chicago locals mainly, while casuals are more dispersed and more likely to be tourists.\n:::\n\n## Findings and suggestions\n\n::: justify\nBased on the previous analysis we can conclude that:\n\n-   Most member customers are Chicago locals and use Cyclistic bikes for daily routine activities, especially to commute to work.\n-   Casual customers are more dispersed, use Cyclistic bikes for leisure, and are more likely to be tourists.\n\nBeing the two groups fundamentally different between each other, it might be hard to convert casuals into members. However we can provide some potentially useful suggestions anyway:\n\n-   Gather more data on casual riders with surveys. Ask about their home addresses, daily habits, work, etc.\n-   Develop a dedicated social media campaign targeted at casual customers on weekends, specifically. A clever and low-cost idea might be asking the customers to share their weekend rides with Cyclistic on social media (in exchange for some discounts, etc.).\n-   Adopt a more flexible pricing structure, by offering something like a weekend-only membership. Also develop a plan to charge casual customers based on 'ride_length'.\n-   Consider cutting investments on docked bikes, and focus on non-docked ones.\n-   Consider an expansion to Chicago neighborhoods.\n-   Consider partnerships with local enterprises, like offering discounted memberships for employees.\n:::\n\n## Source code\n\n::: justify\nFor a different take on this same case study, look at the [source code](https://github.com/G-Bez/Cyclistic-case-study) I uploaded to github, where I also used [renv](https://rstudio.github.io/renv/articles/renv.html) for dependency management, and [targets](https://books.ropensci.org/targets/) for workflow management. Follow the instructions in order to reproduce the analysis.\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}